{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install environment\n",
    "pip install --upgrade \"git+https://github.com/JEFworks-Lab/STalign.git\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refer to example code within STalign\n",
    "# https://github.com/JEFworks-Lab/STalign/blob/main/docs/notebooks/xenium-heimage-alignment.ipynb\n",
    "# Tested on Python=3.11.11\n",
    "# Other dependencies are described in STalign original repo.\n",
    "# \n",
    "# Please Note: This method requires to provide pairs of landmarks: pointsI and pointsJ\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import tifffile as tf\n",
    "from STalign import STalign\n",
    "import math\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cell_loc(HE_quant_fn, col_name_x='Centroid X µm', col_name_y='Centroid Y µm'):\n",
    "    HE_quant_df = pd.read_csv(HE_quant_fn, sep='\\t')\n",
    "    he_x = HE_quant_df[col_name_x]\n",
    "    he_y = HE_quant_df[col_name_y]\n",
    "    source = np.array([he_x, he_y]).T\n",
    "    return source\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_rotation_translation(matrix):\n",
    "    # Calculate rotation angle in degrees\n",
    "    rotation_angle = math.degrees(math.atan2(matrix[1, 0], matrix[0, 0]))\n",
    "    # Calculate translation distance\n",
    "    translation_distance = math.sqrt(matrix[0, 2]**2 + matrix[1, 2]**2)\n",
    "\n",
    "    return rotation_angle, translation_distance\n",
    "\n",
    "def draw_points(source_points, target_points, title):\n",
    "    plt.figure(1)\n",
    "    plt.scatter(source_points[:, 1], source_points[:, 0], c='r', s=10)\n",
    "    plt.scatter(target_points[:, 1], target_points[:, 0], c='b', s=10)\n",
    "    plt.legend([\"HE\", \"MxIF\"])\n",
    "    plt.title(title)\n",
    "    plt.axis('equal')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def STalign_registration(HE_quant_fn, MxIF_quant_fn, HE_img_fn):\n",
    "    HE_centroids = get_cell_loc(HE_quant_fn)   # you may need to specify column names to get the cell coordinates\n",
    "    MxIF_centroids = get_cell_loc(MxIF_quant_fn)\n",
    "\n",
    "    xM = HE_centroids[:, 0]\n",
    "    yM = HE_centroids[:, 1]\n",
    "    xN = MxIF_centroids[:, 0]\n",
    "    yN = MxIF_centroids[:, 1]\n",
    "\n",
    "    he_img = tf.TiffFile(HE_img_fn).pages[0].asarray().astype(np.float)  # read the images\n",
    "\n",
    "    Inorm = STalign.normalize(he_img)\n",
    "    I = Inorm.transpose(2,0,1)\n",
    "    YI = np.array(range(I.shape[1]))*1. # needs to be longs not doubles for STalign.transform later so multiply by 1.\n",
    "    XI = np.array(range(I.shape[2]))*1. # needs to be longs not doubles for STalign.transform later so multiply by 1.\n",
    "\n",
    "    XJ,YJ,M = STalign.rasterize(xM, yM, dx=30, draw=0)\n",
    "    J = np.vstack((M, M, M)) # make into 3xNxM\n",
    "    # normalize\n",
    "    J = STalign.normalize(J)\n",
    "\n",
    "    # Randomly select 4 points from HE_centroids and the corresponding points from MxIF_centroids\n",
    "    indices = np.random.choice(len(xM), 4, replace=False)\n",
    "    selected_HE_points = HE_centroids[indices]\n",
    "    selected_MxIF_points = MxIF_centroids[indices]\n",
    "\n",
    "    temp = selected_HE_points[:,0].copy()\n",
    "    selected_HE_points[:,0]  = selected_HE_points[:,1]\n",
    "    selected_HE_points[:,1]  =  temp\n",
    "\n",
    "    temp = selected_MxIF_points[:,0].copy()\n",
    "    selected_MxIF_points[:,0]  = selected_MxIF_points[:,1]\n",
    "    selected_MxIF_points[:,1]  =  temp\n",
    "\n",
    "    pointsI = selected_HE_points\n",
    "    pointsJ = selected_MxIF_points\n",
    "\n",
    "    L,T = STalign.L_T_from_points(pointsI,pointsJ)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        torch.set_default_device('cuda:0')\n",
    "    else:\n",
    "        torch.set_default_device('cpu')\n",
    "\n",
    "    #  run LDDMM\n",
    "    if torch.cuda.is_available():\n",
    "        device = 'cuda:0'\n",
    "    else:\n",
    "        device = 'cpu'\n",
    "\n",
    "    # keep all other parameters default\n",
    "    params = {'L':L,'T':T,\n",
    "            'niter':2000,\n",
    "            'pointsI':pointsI,\n",
    "            'pointsJ':pointsJ,\n",
    "            'device':device,\n",
    "            'sigmaM':0.15, \n",
    "            'sigmaB':0.10,\n",
    "            'sigmaA':0.11,\n",
    "            'epV': 10,\n",
    "            'muB': torch.tensor([0,0,0]), # black is background in target\n",
    "            'muA': torch.tensor([1,1,1]) # use white as artifact \n",
    "            }\n",
    "\n",
    "    out = STalign.LDDMM([YI,XI],I,[YJ,XJ],J,**params)\n",
    "    A = out['A']\n",
    "    v = out['v']\n",
    "    xv = out['xv']\n",
    "\n",
    "    return A, v, xv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'eval_utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 13\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#  Quantitatively evaluate the alignment results\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# 1. calculate delta theta and delta translation based on the homography matrix.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# 2. Apply the homography matrix to the manually labeled landmarks of image 1, and compare with the landmarks of image 2, calculate delta distance.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# }\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# '''\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01meval_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     15\u001b[0m DEBUG \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     17\u001b[0m Sec \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'eval_utils'"
     ]
    }
   ],
   "source": [
    "#  Quantitatively evaluate the alignment results\n",
    "# 1. calculate delta theta and delta translation based on the homography matrix.\n",
    "# 2. Apply the homography matrix to the manually labeled landmarks of image 1, and compare with the landmarks of image 2, calculate delta distance.\n",
    "\n",
    "# add setting.json to the .vscode folder\n",
    "# '''\n",
    "# {\n",
    "#     \"python.analysis.extraPaths\": [\n",
    "#         \"./MultimodalityHistoComb/release/eval\"\n",
    "#     ]\n",
    "# }\n",
    "# '''\n",
    "from eval_utils import *\n",
    "\n",
    "DEBUG = False\n",
    "\n",
    "Sec = 2\n",
    "\n",
    "HE_pixel_size = 0.2201  # unit micron\n",
    "MxIF_pixel_size = 0.325\n",
    "\n",
    "core_list_fn = \"MultimodalityHistoComb/release/core_list.txt\"\n",
    "core_list = open(core_list_fn, 'r').readlines()\n",
    "roi_id_list = []\n",
    "for core in core_list:\n",
    "    roi_id = core.split(\".\")[0]\n",
    "    roi_id_list.append(roi_id)\n",
    "\n",
    "\n",
    "img_data_dir = \"/Users/jjiang10/Data/OV_TMA\"  #TODO: change to your own data path\n",
    "output_dir = \"/Users/jjiang10/Data/OV_TMA/align_eval\"  #TODO: change to your own data path\n",
    "\n",
    "data_root_dir = \"/temp/Ovarian_TMA\"  #TODO: change to your own data path\n",
    "eval_data_root = os.path.join(data_root_dir, \"AlignmentEval\", \"GroundTruthEvaluation\")\n",
    "anno_data_root = os.path.join(data_root_dir, \"AlignmentEval\", \"GroundTruthAnnotation\")\n",
    "# /temp/Ovarian_TMA/AlignmentEval/QuPathAnnoProj_MxIF/export/\n",
    "HE_cell_quant_fn = os.path.join(data_root_dir, \"AlignmentEval\", \"QuPathAnnoProj_HE\", \"export\")\n",
    "MxIF_cell_quant_fn = os.path.join(data_root_dir, \"AlignmentEval\", \"QuPathAnnoProj_MxIF\", \"export\")\n",
    "if Sec == 1:\n",
    "    # Sec1\n",
    "    ground_truth_output_dir = os.path.join(eval_data_root, \"GT_HE_Sec1_MxIF\")\n",
    "    HE_export_dir = os.path.join(anno_data_root, \"HE_Sec1\")\n",
    "elif Sec == 2:\n",
    "    # Sec2\n",
    "    ground_truth_output_dir = os.path.join(eval_data_root, \"GT_HE_Sec2_MxIF\")\n",
    "    HE_export_dir = os.path.join(anno_data_root, \"HE_Sec2\")\n",
    "else:\n",
    "    raise Exception(\"Undefined Section\")\n",
    "\n",
    "MxIF_export_dir = os.path.join(anno_data_root, \"MxIF_Sec1\")\n",
    "\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "output_csv_fn = os.path.join(output_dir, \"STalign_alignment_eval_Sec%d.csv\" % Sec)\n",
    "df = pd.DataFrame(columns=[\"ROI\", \"GT_dist\", \"Test_dist\", \"GT_angle\", \"Test_angle\", \"GT_landmark\", \"Test_landmark\"])\n",
    "\n",
    "for roi in roi_id_list:\n",
    "    print(\"Processing %s\" % roi)\n",
    "    HE_landmarks_fn = os.path.join(HE_export_dir, roi+\"_align_anno_8.csv\")\n",
    "    MxIF_landmarks_fn = os.path.join(MxIF_export_dir, roi+\"_align_anno_8.csv\")\n",
    "    point_sort_fn = os.path.join(data_root_dir, \"GroundTruthAnnotation\", \"Landmark_correspondence\", \"Sec%d\" %Sec, roi+\".csv\")\n",
    "\n",
    "    gt_trans_fn = os.path.join(eval_data_root, \"GT_HE_Sec%d_MxIF\" % Sec, roi+\"_gt_trans.npy\")\n",
    "\n",
    "    HE_img_path = os.path.join(img_data_dir, f'HE_{roi}.tif')\n",
    "    MxIF_img_path = os.path.join(img_data_dir, f'MxIF_{roi}.ome.tif')\n",
    "\n",
    "    # /temp/Ovarian_TMA/AlignmentEval/QuPathAnnoProj_MxIF/export/A-8_StarDist_QUANT.tsv\n",
    "    HE_quant_fn = os.path.join(HE_cell_quant_fn, roi+\"_StarDist_QUANT.tsv\")\n",
    "    MxIF_quant_fn = os.path.join(MxIF_cell_quant_fn, roi+\"_StarDist_QUANT.tsv\")\n",
    "\n",
    "\n",
    "    aff_matrix, _, _ = STalign_registration(HE_quant_fn, MxIF_quant_fn, HE_img_path)\n",
    "\n",
    "    # HE_img, MxIF_img = load_images(HE_img_path, MxIF_img_path)\n",
    "    # aligned_img, good_matches, keypoints1, keypoints2, aff_matrix = sift_alignment(HE_img, MxIF_img)\n",
    "\n",
    "    sorted_HE_landmarks, sorted_MxIF_landmarks = get_sorted_annotation_landmark_pairs(HE_landmarks_fn, MxIF_landmarks_fn, point_sort_fn)\n",
    "    sorted_HE_landmarks_um = sorted_HE_landmarks * HE_pixel_size\n",
    "    sorted_MxIF_landmarks_um = sorted_MxIF_landmarks * MxIF_pixel_size\n",
    "\n",
    "    gt_M = np.load(gt_trans_fn)\n",
    "\n",
    "    # check distance between transformed source landmark points and target landmark points\n",
    "    gt_trans_HE_landmarks_um = apply_aff_trans2points(sorted_HE_landmarks_um, gt_M)\n",
    "    gt_landmark_dist = calculate_transformed_landmark_dist(gt_trans_HE_landmarks_um, sorted_MxIF_landmarks_um)\n",
    "\n",
    "    trans_HE_landmarks_um = apply_aff_trans2points(sorted_HE_landmarks, aff_matrix)*MxIF_pixel_size\n",
    "    test_landmark_dist = calculate_transformed_landmark_dist(trans_HE_landmarks_um, sorted_MxIF_landmarks_um)\n",
    "\n",
    "    gt_rotation_angle, gt_translation_distance = get_rotation_translation(gt_M)\n",
    "    test_rotation_angle, test_translation_distance = get_rotation_translation(aff_matrix)\n",
    "    if DEBUG:\n",
    "        draw_points(gt_trans_HE_landmarks_um, sorted_MxIF_landmarks_um, \"Landmarks with ground truth transformation\")\n",
    "        draw_points(trans_HE_landmarks_um, sorted_MxIF_landmarks_um, \"Landmarks with test transformation\")\n",
    "\n",
    "        print(\"\\t Distance differences: %f\\t %f\" % (gt_landmark_dist, test_landmark_dist))\n",
    "    data_list = [roi, gt_translation_distance, test_translation_distance, gt_rotation_angle, test_rotation_angle, gt_landmark_dist, test_landmark_dist] \n",
    "\n",
    "    df = pd.concat([pd.DataFrame([data_list], columns=df.columns), df], ignore_index=True)\n",
    "\n",
    "df.to_csv(output_csv_fn)\n",
    "\n",
    "# draw plots\n",
    "vals = list(abs(df['Test_landmark']-df['GT_landmark']))\n",
    "avg = sum(vals)/len(vals)\n",
    "plt.figure(figsize=(4,3), dpi=300)\n",
    "plt.xlabel(r'$\\mu$' + \"m\")\n",
    "plt.ylabel(\"percentage\")\n",
    "sns.histplot(vals, stat='percent', bins=5, shrink=0.5, color='red', edgecolor=\"black\")\n",
    "plt.axvline(avg, 0, 0.8, color='brown', linestyle='--')\n",
    "plt.title(r'$\\Delta$' +\" Distance\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "vals = list(abs(df['Test_angle']-df['GT_angle']))\n",
    "avg = sum(vals)/len(vals)\n",
    "plt.figure(figsize=(4,3), dpi=300)\n",
    "plt.xlabel(\"Degree\" + '$^\\circ$')\n",
    "plt.ylabel(\"percentage\")\n",
    "sns.histplot(vals, stat='percent', bins=5, shrink=0.5, color='green', edgecolor=\"black\")\n",
    "plt.axvline(avg, 0, 0.8, color='brown', linestyle='--')\n",
    "plt.title(r'$\\Delta$' + \" Rotation\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "vals = list(abs(df['Test_dist']-df['GT_dist']))\n",
    "avg = sum(vals)/len(vals)\n",
    "plt.figure(figsize=(4,3), dpi=300)\n",
    "plt.xlabel(r'$\\mu$' + \"m\")\n",
    "plt.ylabel(\"percentage\")\n",
    "sns.histplot(vals, stat='percent', bins=5, shrink=0.5, color='blue', edgecolor=\"black\")\n",
    "plt.axvline(avg, 0, 0.8, color='brown', linestyle='--')\n",
    "plt.title(r'$\\Delta$' + \" Translation\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alignment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
