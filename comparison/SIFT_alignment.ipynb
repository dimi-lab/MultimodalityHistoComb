{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install environment\n",
    "pip install opencv-python, tifffile\n",
    "pip install numpy, matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import tifffile as tiff\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load two TIFF images\n",
    "def load_images(image1_path, image2_path):\n",
    "    img1 = tiff.imread(image1_path)\n",
    "    img2 = tiff.TiffFile(image2_path)\n",
    "    img1_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "    img2_gray = img2.pages[0].asarray().squeeze()\n",
    "    # Invert image, very important step, as MxIF is dark field image, while H&E is bright field image\n",
    "    # Alignment will fail if there is no inversion\n",
    "    img2_gray = cv2.bitwise_not(img2_gray) \n",
    "    return img1_gray, img2_gray\n",
    "\n",
    "# Apply SIFT feature detection and alignment\n",
    "def sift_alignment(img1, img2):\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints1, descriptors1 = sift.detectAndCompute(img1, None)\n",
    "    keypoints2, descriptors2 = sift.detectAndCompute(img2, None)\n",
    "    \n",
    "    # Use FLANN-based matcher\n",
    "    index_params = dict(algorithm=1, trees=5)\n",
    "    search_params = dict(checks=50)\n",
    "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "    matches = flann.knnMatch(descriptors1, descriptors2, k=2)\n",
    "    \n",
    "    # Apply ratio test\n",
    "    good_matches = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < 0.75 * n.distance:\n",
    "            good_matches.append(m)\n",
    "    \n",
    "    # Extract matched keypoints\n",
    "    src_pts = np.float32([keypoints1[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "    dst_pts = np.float32([keypoints2[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "    \n",
    "    # Compute homography matrix\n",
    "    matrix, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "    \n",
    "    # Warp image\n",
    "    aligned_img = cv2.warpPerspective(img1, matrix, (img2.shape[1], img2.shape[0]))\n",
    "    return aligned_img, good_matches, keypoints1, keypoints2, matrix\n",
    "\n",
    "def draw_points(source_points, target_points, title):\n",
    "    plt.figure(1)\n",
    "    plt.scatter(source_points[:, 1], source_points[:, 0], c='r', s=10)\n",
    "    plt.scatter(target_points[:, 1], target_points[:, 0], c='b', s=10)\n",
    "    plt.legend([\"HE\", \"MxIF\"])\n",
    "    plt.title(title)\n",
    "    plt.axis('equal')\n",
    "    plt.show()\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.15367310937112738, 144.9718052252821)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "def get_rotation_translation(matrix):\n",
    "    # Calculate rotation angle in degrees\n",
    "    rotation_angle = math.degrees(math.atan2(matrix[1, 0], matrix[0, 0]))\n",
    "    # Calculate translation distance\n",
    "    translation_distance = math.sqrt(matrix[0, 2]**2 + matrix[1, 2]**2)\n",
    "\n",
    "    return rotation_angle, translation_distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_image_alignment(img1, img2, aligned_img):\n",
    "    # Plot results\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.title(\"Original Image 1\")\n",
    "    plt.imshow(img1, cmap='gray')\n",
    "# plt.plot([keypoint.pt[0] for keypoint in keypoints1], [keypoint.pt[1] for keypoint in keypoints1], 'ro')\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.title(\"Original Image 2\")\n",
    "    plt.imshow(img2, cmap='gray')\n",
    "# plt.plot([keypoint.pt[0] for keypoint in keypoints2], [keypoint.pt[1] for keypoint in keypoints2], 'bo')\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.title(\"Aligned Image 1\")\n",
    "    plt.imshow(aligned_img, cmap='gray')\n",
    "# plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Quantitatively evaluate the alignment results\n",
    "# 1. calculate delta theta and delta translation based on the homography matrix.\n",
    "# 2. Apply the homography matrix to the manually labeled landmarks of image 1, and compare with the landmarks of image 2, calculate delta distance.\n",
    "\n",
    "# add setting.json to the .vscode folder\n",
    "# '''\n",
    "# {\n",
    "#     \"python.analysis.extraPaths\": [\n",
    "#         \"./MultimodalityHistoComb/release/eval\"\n",
    "#     ]\n",
    "# }\n",
    "# '''\n",
    "\n",
    "\n",
    "from eval_utils import *\n",
    "\n",
    "DEBUG = False\n",
    "\n",
    "Sec = 2\n",
    "\n",
    "HE_pixel_size = 0.2201  # unit micron\n",
    "MxIF_pixel_size = 0.325\n",
    "\n",
    "core_list_fn = \"MultimodalityHistoComb/release/core_list.txt\"\n",
    "core_list = open(core_list_fn, 'r').readlines()\n",
    "roi_id_list = []\n",
    "for core in core_list:\n",
    "    roi_id = core.split(\".\")[0]\n",
    "    roi_id_list.append(roi_id)\n",
    "\n",
    "\n",
    "img_data_dir = \"/Users/jjiang10/Data/OV_TMA\"  #TODO: change to your own data path\n",
    "output_dir = \"/Users/jjiang10/Data/OV_TMA/align_eval\"  #TODO: change to your own data path\n",
    "\n",
    "data_root_dir = \"/temp/Ovarian_TMA\"  #TODO: change to your own data path\n",
    "eval_data_root = os.path.join(data_root_dir, \"AlignmentEval\", \"GroundTruthEvaluation\")\n",
    "anno_data_root = os.path.join(data_root_dir, \"AlignmentEval\", \"GroundTruthAnnotation\")\n",
    "if Sec == 1:\n",
    "    # Sec1\n",
    "    ground_truth_output_dir = os.path.join(eval_data_root, \"GT_HE_Sec1_MxIF\")\n",
    "    HE_export_dir = os.path.join(anno_data_root, \"HE_Sec1\")\n",
    "elif Sec == 2:\n",
    "    # Sec2\n",
    "    ground_truth_output_dir = os.path.join(eval_data_root, \"GT_HE_Sec2_MxIF\")\n",
    "    HE_export_dir = os.path.join(anno_data_root, \"HE_Sec2\")\n",
    "else:\n",
    "    raise Exception(\"Undefined Section\")\n",
    "\n",
    "MxIF_export_dir = os.path.join(anno_data_root, \"MxIF_Sec1\")\n",
    "\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "output_csv_fn = os.path.join(output_dir, \"SIFT_alignment_eval_Sec%d.csv\" % Sec)\n",
    "df = pd.DataFrame(columns=[\"ROI\", \"GT_dist\", \"Test_dist\", \"GT_angle\", \"Test_angle\", \"GT_landmark\", \"Test_landmark\"])\n",
    "\n",
    "for roi in roi_id_list:\n",
    "    print(\"Processing %s\" % roi)\n",
    "    HE_landmarks_fn = os.path.join(HE_export_dir, roi+\"_align_anno_8.csv\")\n",
    "    MxIF_landmarks_fn = os.path.join(MxIF_export_dir, roi+\"_align_anno_8.csv\")\n",
    "    point_sort_fn = os.path.join(data_root_dir, \"GroundTruthAnnotation\", \"Landmark_correspondence\", \"Sec%d\" %Sec, roi+\".csv\")\n",
    "\n",
    "    gt_trans_fn = os.path.join(eval_data_root, \"GT_HE_Sec%d_MxIF\" % Sec, roi+\"_gt_trans.npy\")\n",
    "\n",
    "    HE_img_path = os.path.join(img_data_dir, f'HE_{roi}.tif')\n",
    "    MxIF_img_path = os.path.join(img_data_dir, f'MxIF_{roi}.ome.tif')\n",
    "    HE_img, MxIF_img = load_images(HE_img_path, MxIF_img_path)\n",
    "    aligned_img, good_matches, keypoints1, keypoints2, aff_matrix = sift_alignment(HE_img, MxIF_img)\n",
    "\n",
    "    sorted_HE_landmarks, sorted_MxIF_landmarks = get_sorted_annotation_landmark_pairs(HE_landmarks_fn, MxIF_landmarks_fn, point_sort_fn)\n",
    "    sorted_HE_landmarks_um = sorted_HE_landmarks * HE_pixel_size\n",
    "    sorted_MxIF_landmarks_um = sorted_MxIF_landmarks * MxIF_pixel_size\n",
    "\n",
    "    gt_M = np.load(gt_trans_fn)\n",
    "\n",
    "    # check distance between transformed source landmark points and target landmark points\n",
    "    gt_trans_HE_landmarks_um = apply_aff_trans2points(sorted_HE_landmarks_um, gt_M)\n",
    "    gt_landmark_dist = calculate_transformed_landmark_dist(gt_trans_HE_landmarks_um, sorted_MxIF_landmarks_um)\n",
    "\n",
    "    trans_HE_landmarks_um = apply_aff_trans2points(sorted_HE_landmarks, aff_matrix)*MxIF_pixel_size\n",
    "    test_landmark_dist = calculate_transformed_landmark_dist(trans_HE_landmarks_um, sorted_MxIF_landmarks_um)\n",
    "\n",
    "    gt_rotation_angle, gt_translation_distance = get_rotation_translation(gt_M)\n",
    "    test_rotation_angle, test_translation_distance = get_rotation_translation(aff_matrix)\n",
    "    if DEBUG:\n",
    "        draw_points(gt_trans_HE_landmarks_um, sorted_MxIF_landmarks_um, \"Landmarks with ground truth transformation\")\n",
    "        draw_points(trans_HE_landmarks_um, sorted_MxIF_landmarks_um, \"Landmarks with test transformation\")\n",
    "\n",
    "        print(\"\\t Distance differences: %f\\t %f\" % (gt_landmark_dist, test_landmark_dist))\n",
    "    data_list = [roi, gt_translation_distance, test_translation_distance, gt_rotation_angle, test_rotation_angle, gt_landmark_dist, test_landmark_dist] \n",
    "\n",
    "    df = pd.concat([pd.DataFrame([data_list], columns=df.columns), df], ignore_index=True)\n",
    "\n",
    "df.to_csv(output_csv_fn)\n",
    "\n",
    "# draw plots\n",
    "\n",
    "# draw plots\n",
    "vals = list(abs(df['Test_landmark']-df['GT_landmark']))* HE_pixel_size\n",
    "avg = sum(vals)/len(vals)\n",
    "plt.figure(figsize=(4,3), dpi=300)\n",
    "plt.xlabel(r'$\\mu$' + \"m\")\n",
    "plt.ylabel(\"percentage\")\n",
    "sns.histplot(vals, stat='percent', bins=5, shrink=0.5, color='red', edgecolor=\"black\")\n",
    "plt.axvline(avg, 0, 0.8, color='brown', linestyle='--')\n",
    "plt.title(r'$\\Delta$' +\" Distance\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "vals = list(abs(df['Test_angle']-df['GT_angle']))\n",
    "avg = sum(vals)/len(vals)\n",
    "plt.figure(figsize=(4,3), dpi=300)\n",
    "plt.xlabel(\"Degree\" + '$^\\circ$')\n",
    "plt.ylabel(\"percentage\")\n",
    "sns.histplot(vals, stat='percent', bins=5, shrink=0.5, color='green', edgecolor=\"black\")\n",
    "plt.axvline(avg, 0, 0.8, color='brown', linestyle='--')\n",
    "plt.title(r'$\\Delta$' + \" Rotation\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "vals = list(abs(df['Test_dist']-df['GT_dist'])) * HE_pixel_size\n",
    "avg = sum(vals)/len(vals)\n",
    "plt.figure(figsize=(4,3), dpi=300)\n",
    "plt.xlabel(r'$\\mu$' + \"m\")\n",
    "plt.ylabel(\"percentage\")\n",
    "sns.histplot(vals, stat='percent', bins=5, shrink=0.5, color='blue', edgecolor=\"black\")\n",
    "plt.axvline(avg, 0, 0.8, color='brown', linestyle='--')\n",
    "plt.title(r'$\\Delta$' + \" Translation\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alignment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
