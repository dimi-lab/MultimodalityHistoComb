{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-30T09:29:51.288785100Z",
     "start_time": "2023-12-30T09:29:51.282785500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import pickle\n",
    "import natsort\n",
    "from probreg import cpd, gmmtree, filterreg, bcpd, math_utils\n",
    "import copy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-30T09:29:46.159480700Z",
     "start_time": "2023-12-30T09:29:46.119457700Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_cell_loc_from_df(HE_quant_df, MxIF_quant_df):\n",
    "    he_x = HE_quant_df[\"Centroid X µm\"]\n",
    "    he_y = HE_quant_df[\"Centroid Y µm\"]\n",
    "    mxif_x = MxIF_quant_df[\"Centroid X µm\"]\n",
    "    mxif_y = MxIF_quant_df[\"Centroid Y µm\"]\n",
    "\n",
    "    source = np.array([he_x, he_y]).T\n",
    "    target = np.array([mxif_x, mxif_y]).T\n",
    "    return source, target\n",
    "\n",
    "def align_cell_segmentation(source, target):\n",
    "    # compute cpd registration\n",
    "    # set update_scale to False, as the cell locations were denoted with microns (calculated based on pixel size)\n",
    "    # TODO: But how to apply the affine transformation obtained from this registration if the pixel sizes are different?\n",
    "    # TODO: sx=sy=source_pixel_size/target_pixel_size\n",
    "    tf_param, sigma2, q = cpd.registration_cpd(source, target, maxiter=150, update_scale=False)\n",
    "\n",
    "    result = copy.deepcopy(source)\n",
    "    r_points = tf_param.transform(result)\n",
    "\n",
    "    return tf_param, r_points, sigma2, q\n",
    "\n",
    "def get_TMA_core_list(img_path: str) -> list:\n",
    "    img_fn_list = os.listdir(img_path)\n",
    "    roi_list = [i.split(\"_\")[0] for i in img_fn_list]\n",
    "    return list(set(roi_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "HE_pxiel_size = 0.2201  # unit micron\n",
    "MxIF_pixel_size = 0.325\n",
    "\n",
    "pix_scale = HE_pxiel_size / MxIF_pixel_size\n",
    "target_pixel_size = MxIF_pixel_size\n",
    "\n",
    "\n",
    "def save_CPD_trans(MxIF_export_dir, HE_export_dir, cpd_output_dir):\n",
    "    ROI_list = natsort.natsorted(get_TMA_core_list(MxIF_export_dir))\n",
    "    for roi_id in ROI_list:\n",
    "        print(\"\\t Processing: %s\" % roi_id)\n",
    "        trans_fn = os.path.join(cpd_output_dir, roi_id + \"_trans.dat\")\n",
    "        if os.path.exists(trans_fn):\n",
    "            print(\"\\t\\t File already exist\")\n",
    "        else:    \n",
    "            HE_quant_fn = os.path.join(HE_export_dir, roi_id + \"_\" + seg + \"_QUANT.tsv\")\n",
    "            MxIF_quant_fn = os.path.join(MxIF_export_dir, roi_id + \"_\" + seg + \"_QUANT.tsv\")\n",
    "            HE_quant_df = pd.read_csv(HE_quant_fn, sep='\\t')\n",
    "            MxIF_quant_df = pd.read_csv(MxIF_quant_fn, sep='\\t')\n",
    "            source, target = get_cell_loc_from_df(HE_quant_df, MxIF_quant_df)  # without cell density\n",
    "            print(\"\\t\\t Number of points: (%d, %d)\" % (len(source), len(target)))\n",
    "\n",
    "            tf_param, r_points, sigma2, q = align_cell_segmentation(source, target)\n",
    "\n",
    "            R = tf_param.rot\n",
    "            T = tf_param.t\n",
    "            M = np.array([[pix_scale * R[0, 0], pix_scale * R[0, 1], T[0] / target_pixel_size],\n",
    "                          [pix_scale * R[1, 0], pix_scale * R[1, 1], T[1] / target_pixel_size]]).astype(float)\n",
    "\n",
    "            theta = math.atan(R[1, 0]/R[0, 0])\n",
    "            degrees = theta * ( 180.0 / math.pi )\n",
    "            s = tf_param.scale\n",
    "            delta = math.sqrt(M[0, 2]**2 + M[1, 2]**2)\n",
    "\n",
    "            data = [theta, degrees, s, delta, M]\n",
    "            with open(trans_fn, \"wb\") as f:\n",
    "                pickle.dump(data, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "if \"windows\" in platform.system().lower():\n",
    "    data_root_dir = r\"\\\\mfad\\researchmn\\HCPR\\HCPR-GYNECOLOGICALTUMORMICROENVIRONMENT\\Archive\\WSIs\\Ovarian_TMA\\AlignmentEval\"\n",
    "elif \"linux\" in platform.system().lower():\n",
    "    data_root_dir = \"/infodev1/non-phi-data/junjiang/Ovarian_TMA/AlignmentEval\"\n",
    "else:\n",
    "    raise Exception(\"platform not defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Sec1 for StarDist\n",
      "processing: A-8\n",
      "File already exist\n",
      "processing: A-22\n",
      "File already exist\n",
      "processing: B-9\n",
      "File already exist\n",
      "processing: B-11\n",
      "File already exist\n",
      "processing: B-12\n",
      "File already exist\n",
      "processing: B-15\n",
      "File already exist\n",
      "processing: B-21\n",
      "File already exist\n",
      "processing: C-10\n",
      "File already exist\n",
      "processing: C-15\n",
      "File already exist\n",
      "processing: C-21\n",
      "File already exist\n",
      "processing: C-24\n",
      "File already exist\n",
      "processing: D-6\n",
      "File already exist\n",
      "processing: E-13\n",
      "File already exist\n",
      "processing: F-10\n",
      "File already exist\n",
      "processing: G-7\n",
      "File already exist\n",
      "processing: H-13\n",
      "File already exist\n",
      "processing: H-16\n",
      "File already exist\n",
      "processing: H-20\n",
      "File already exist\n",
      "processing: I-15\n",
      "File already exist\n",
      "processing: I-17\n",
      "Number of points: (3659, 4958)\n",
      "Running Sec1 for Watershed\n",
      "processing: A-8\n",
      "Number of points: (3737, 2917)\n",
      "processing: A-22\n",
      "Number of points: (2261, 1900)\n",
      "processing: B-9\n",
      "Number of points: (5135, 4135)\n",
      "processing: B-11\n",
      "Number of points: (3586, 2794)\n",
      "processing: B-12\n",
      "Number of points: (4546, 3859)\n"
     ]
    }
   ],
   "source": [
    "sec_list = [\"Sec1\", \"Sec2\"]\n",
    "seg_method_list = [\"StarDist\", \"Watershed\"]\n",
    "\n",
    "for sec in sec_list:\n",
    "    if sec == \"Sec1\":\n",
    "        for seg in seg_method_list:\n",
    "            print(\"Running %s for %s\" % (sec, seg))\n",
    "            if seg == \"StarDist\":\n",
    "                HE_export_dir = os.path.join(data_root_dir, \"QuPathAnnoProj_HE_Sec1\", \"export\")\n",
    "                MxIF_export_dir =os.path.join(data_root_dir, \"QuPathAnnoProj_MxIF\", \"export\")\n",
    "                cpd_output_dir = os.path.join(data_root_dir, \"Sec1_stardist_CPD\")\n",
    "            elif seg == \"Watershed\":\n",
    "                HE_export_dir = os.path.join(data_root_dir, \"QuPathAnnoProj_HE_Sec1_watershed\", \"export\")\n",
    "                MxIF_export_dir = os.path.join(data_root_dir, \"QuPathAnnoProj_MxIF_watershed\", \"export\")\n",
    "                cpd_output_dir = os.path.join(data_root_dir, \"Sec1_watershed_CPD\")\n",
    "            else:\n",
    "                raise Exception(\"Unknown segmentation method\")\n",
    "            \n",
    "            save_CPD_trans(MxIF_export_dir, HE_export_dir, cpd_output_dir)\n",
    "    elif sec == \"Sec2\":\n",
    "        for seg in seg_method_list:\n",
    "            print(\"Running %s for %s\" % (sec, seg))\n",
    "            if seg == \"StarDist\":\n",
    "                HE_export_dir = os.path.join(data_root_dir, \"QuPathAnnoProj_HE_Sec2\", \"export\")\n",
    "                MxIF_export_dir = os.path.join(data_root_dir, \"QuPathAnnoProj_MxIF\", \"export\")\n",
    "                cpd_output_dir = os.path.join(data_root_dir, \"Sec2_stardist_CPD\")\n",
    "            elif seg == \"Watershed\":\n",
    "                HE_export_dir = os.path.join(data_root_dir, \"QuPathAnnoProj_HE_Sec2_watershed\", \"export\")\n",
    "                MxIF_export_dir = os.path.join(data_root_dir, \"QuPathAnnoProj_MxIF_watershed\", \"export\")\n",
    "                cpd_output_dir = os.path.join(data_root_dir, \"Sec2_watershed_CPD\")\n",
    "            else:\n",
    "                raise Exception(\"Unknown segmentation method\")\n",
    "\n",
    "            save_CPD_trans(MxIF_export_dir, HE_export_dir, cpd_output_dir)\n",
    "    else:\n",
    "        raise Exception(\"Unknown section name\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
