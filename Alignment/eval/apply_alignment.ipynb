{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import pickle\n",
    "import natsort\n",
    "from probreg import cpd, gmmtree, filterreg, bcpd, math_utils\n",
    "import copy\n",
    "import pandas as pd\n",
    "from scipy.spatial import KDTree\n",
    "from scipy.stats import gaussian_kde\n",
    "import tifffile as tf\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "if \"windows\" in platform.system().lower():\n",
    "    data_root_dir = r\"\\\\mfad\\researchmn\\HCPR\\HCPR-GYNECOLOGICALTUMORMICROENVIRONMENT\\Archive\\WSIs\\Ovarian_TMA\"\n",
    "elif \"linux\" in platform.system().lower():\n",
    "    data_root_dir = \"/infodev1/non-phi-data/junjiang/Ovarian_TMA\"\n",
    "else:\n",
    "    raise Exception(\"platform not defined\")\n",
    "\n",
    "def get_TMA_core_list(img_path: str) -> list:\n",
    "    img_fn_list = os.listdir(img_path)\n",
    "    roi_list = [i.split(\"_\")[0] for i in img_fn_list]\n",
    "    return list(set(roi_list))\n",
    "\n",
    "ROI_list = natsort.natsorted(get_TMA_core_list(os.path.join(data_root_dir, \"AlignmentEval\", \"Sec1GroundTruth\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trans(trans_fn):\n",
    "    fp = open(trans_fn, 'rb')\n",
    "    data = pickle.load(fp)\n",
    "    fp.close()\n",
    "    return data\n",
    "\n",
    "def get_cell_loc(HE_quant_fn):\n",
    "    HE_quant_df = pd.read_csv(HE_quant_fn, sep='\\t')\n",
    "    he_x = HE_quant_df[\"Centroid X µm\"]\n",
    "    he_y = HE_quant_df[\"Centroid Y µm\"]\n",
    "    source = np.array([he_x, he_y]).T\n",
    "    return source\n",
    "\n",
    "def apply_aff_trans2points(source, M):\n",
    "    '''\n",
    "    source: cell centroids from H&E segmentation (N*2), N is the number of cell\n",
    "    '''\n",
    "    MM = np.vstack((M,np.array([0,0,1])))\n",
    "    new_XY = np.vstack((np.transpose(source), np.ones((1, len(source)))))\n",
    "    transformed_loc = np.dot(M, new_XY)\n",
    "    affined_points = np.transpose(transformed_loc[0:2, :])\n",
    "    return affined_points\n",
    "\n",
    "# def apply_aff_trans2img(he_img, dapi_img, M):\n",
    "#     aff_image = cv2.warpAffine(src=he_img, M=M, dsize=dapi_img.shape)\n",
    "#     return aff_image\n",
    "\n",
    "def calculate_points_affine_rmse(target_points, affined_points, leafsize=10):\n",
    "    target_tree = KDTree(target_points, leafsize=leafsize)\n",
    "    rmse = math_utils.compute_rmse(affined_points, target_tree)\n",
    "    return rmse\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running A-8, Sec1 for StarDist\n",
      "Running A-8, Sec1 for Watershed\n",
      "Running A-8, Sec2 for StarDist\n",
      "Running A-8, Sec2 for Watershed\n",
      "Running A-22, Sec1 for StarDist\n",
      "Running A-22, Sec1 for Watershed\n",
      "Running A-22, Sec2 for StarDist\n",
      "Running A-22, Sec2 for Watershed\n",
      "Running B-9, Sec1 for StarDist\n",
      "Running B-9, Sec1 for Watershed\n",
      "Running B-9, Sec2 for StarDist\n",
      "Running B-9, Sec2 for Watershed\n",
      "Running B-11, Sec1 for StarDist\n",
      "Running B-11, Sec1 for Watershed\n",
      "Running B-11, Sec2 for StarDist\n",
      "Running B-11, Sec2 for Watershed\n",
      "Running B-12, Sec1 for StarDist\n",
      "Running B-12, Sec1 for Watershed\n",
      "Running B-12, Sec2 for StarDist\n",
      "Running B-12, Sec2 for Watershed\n",
      "Running B-15, Sec1 for StarDist\n",
      "Running B-15, Sec1 for Watershed\n",
      "Running B-15, Sec2 for StarDist\n",
      "Running B-15, Sec2 for Watershed\n",
      "Running B-21, Sec1 for StarDist\n",
      "Running B-21, Sec1 for Watershed\n",
      "Running B-21, Sec2 for StarDist\n",
      "Running B-21, Sec2 for Watershed\n",
      "Running C-10, Sec1 for StarDist\n",
      "Running C-10, Sec1 for Watershed\n",
      "Running C-10, Sec2 for StarDist\n",
      "Running C-10, Sec2 for Watershed\n",
      "Running C-15, Sec1 for StarDist\n",
      "Running C-15, Sec1 for Watershed\n",
      "Running C-15, Sec2 for StarDist\n",
      "Running C-15, Sec2 for Watershed\n",
      "Running C-21, Sec1 for StarDist\n",
      "Running C-21, Sec1 for Watershed\n",
      "Running C-21, Sec2 for StarDist\n",
      "Running C-21, Sec2 for Watershed\n",
      "Running C-24, Sec1 for StarDist\n",
      "Running C-24, Sec1 for Watershed\n",
      "Running C-24, Sec2 for StarDist\n",
      "Running C-24, Sec2 for Watershed\n",
      "Running D-6, Sec1 for StarDist\n",
      "Running D-6, Sec1 for Watershed\n",
      "Running D-6, Sec2 for StarDist\n",
      "Running D-6, Sec2 for Watershed\n",
      "Running E-13, Sec1 for StarDist\n",
      "Running E-13, Sec1 for Watershed\n",
      "Running E-13, Sec2 for StarDist\n",
      "Running E-13, Sec2 for Watershed\n",
      "Running F-10, Sec1 for StarDist\n",
      "Running F-10, Sec1 for Watershed\n",
      "Running F-10, Sec2 for StarDist\n",
      "Running F-10, Sec2 for Watershed\n",
      "Running G-7, Sec1 for StarDist\n",
      "Running G-7, Sec1 for Watershed\n",
      "Running G-7, Sec2 for StarDist\n",
      "Running G-7, Sec2 for Watershed\n",
      "Running H-13, Sec1 for StarDist\n",
      "Running H-13, Sec1 for Watershed\n",
      "Running H-13, Sec2 for StarDist\n",
      "Running H-13, Sec2 for Watershed\n",
      "Running H-16, Sec1 for StarDist\n",
      "Running H-16, Sec1 for Watershed\n",
      "Running H-16, Sec2 for StarDist\n",
      "Running H-16, Sec2 for Watershed\n",
      "Running H-20, Sec1 for StarDist\n",
      "Running H-20, Sec1 for Watershed\n",
      "Running H-20, Sec2 for StarDist\n",
      "Running H-20, Sec2 for Watershed\n",
      "Running I-15, Sec1 for StarDist\n",
      "Running I-15, Sec1 for Watershed\n",
      "Running I-15, Sec2 for StarDist\n",
      "Running I-15, Sec2 for Watershed\n",
      "Running I-17, Sec1 for StarDist\n",
      "Running I-17, Sec1 for Watershed\n",
      "Running I-17, Sec2 for StarDist\n",
      "Running I-17, Sec2 for Watershed\n"
     ]
    }
   ],
   "source": [
    "HE_pxiel_size = 0.2201  # unit micron\n",
    "MxIF_pixel_size = 0.325\n",
    "\n",
    "pix_scale = HE_pxiel_size / MxIF_pixel_size\n",
    "target_pixel_size = MxIF_pixel_size\n",
    "\n",
    "sec_list = [\"Sec1\", \"Sec2\"]\n",
    "seg_method_list = [\"StarDist\", \"Watershed\"]\n",
    "\n",
    "for roi_id in ROI_list:\n",
    "    MxIF_img_dir =os.path.join(data_root_dir, \"FOVs\", \"MxIF_FOVs\", \"Slide2050_24Plex\")\n",
    "    mxif_fn = os.path.join(MxIF_img_dir, roi_id + \".tif\")\n",
    "    mxif_img = tf.TiffFile(mxif_fn)\n",
    "    dapi_img = mxif_img.pages[0].asarray().astype(float)\n",
    "    \n",
    "    for sec in sec_list:\n",
    "        if sec == \"Sec1\":\n",
    "            HE_img_dir = os.path.join(data_root_dir, \"FOVs\", \"HE_FOVs\", \"same_section\")            \n",
    "            # Get image\n",
    "            he_fn = os.path.join(HE_img_dir, roi_id + \".tif\")\n",
    "            he_img = tf.TiffFile(he_fn).pages[0].asarray().astype(float)\n",
    "            \n",
    "            # Load ground truth transformation\n",
    "            ground_truth_affine_dir = os.path.join(data_root_dir, \"AlignmentEval\", \"Sec1GroundTruth\")\n",
    "            [gt_theta, gt_degrees, gt_s, gt_delta, gt_M, _] = load_trans(os.path.join(ground_truth_affine_dir, roi_id+\"_trans.dat\"))\n",
    "            \n",
    "            output_dir = os.path.join(data_root_dir, \"AlignmentEval\", \"ApplyAlignment\", \"Sec1Output\")\n",
    "            \n",
    "            for seg in seg_method_list:\n",
    "                print(\"Running %s, %s for %s\" % (roi_id, sec, seg))\n",
    "                if seg == \"StarDist\":\n",
    "                    HE_points_dir = os.path.join(data_root_dir, \"AlignmentEval\", \"QuPathAnnoProj_HE_Sec1\", \"export\")\n",
    "                    MxIF_points_dir =os.path.join(data_root_dir, \"AlignmentEval\", \"QuPathAnnoProj_MxIF\", \"export\")\n",
    "                    cpd_affine_dir = os.path.join(data_root_dir, \"AlignmentEval\", \"Sec1_stardist_CPD\")\n",
    "                elif seg == \"Watershed\":\n",
    "                    HE_points_dir = os.path.join(data_root_dir, \"AlignmentEval\", \"QuPathAnnoProj_HE_Sec1_watershed\", \"export\")\n",
    "                    MxIF_points_dir =os.path.join(data_root_dir, \"AlignmentEval\", \"QuPathAnnoProj_MxIF_watershed\", \"export\")\n",
    "                    cpd_affine_dir = os.path.join(data_root_dir, \"AlignmentEval\", \"Sec1_watershed_CPD\")\n",
    "                else:\n",
    "                    raise Exception(\"Unknown segmentation method\")\n",
    "                \n",
    "                # Get points\n",
    "                HE_quant_fn = os.path.join(HE_points_dir, roi_id + \"_\" + seg + \"_QUANT.tsv\")\n",
    "                HE_points = get_cell_loc(HE_quant_fn)\n",
    "                MxIF_quant_fn = os.path.join(MxIF_points_dir, roi_id + \"_\" + seg + \"_QUANT.tsv\")\n",
    "                MxIF_points = get_cell_loc(MxIF_quant_fn)\n",
    "                \n",
    "                # apply transformation (from annotation) to points (from different cell segmentation methods) and image\n",
    "                gt_affined_points = apply_aff_trans2points(HE_points, gt_M)\n",
    "                gt_affined_HE_img = cv2.warpAffine(src=he_img, M=gt_M, dsize=dapi_img.shape)\n",
    "\n",
    "                # apply transformation (from CPD) to points (from different cell segmentation methods) and image\n",
    "                [theta, degrees, s, delta, M] = load_trans(os.path.join(cpd_affine_dir, roi_id+\"_trans.dat\"))\n",
    "                cpd_affined_points = apply_aff_trans2points(HE_points, M)\n",
    "                cpd_affined_HE_img = cv2.warpAffine(src=he_img, M=M, dsize=dapi_img.shape)\n",
    "                \n",
    "                rmse_gt = calculate_points_affine_rmse(MxIF_points, gt_affined_points, leafsize=10)\n",
    "                rmse_cpd = calculate_points_affine_rmse(MxIF_points, cpd_affined_points, leafsize=10)\n",
    "                \n",
    "                # Save metrics \n",
    "                csv_fn = os.path.join(output_dir, roi_id + \"_\" + seg + \"_metrics.csv\")\n",
    "                fp = open(csv_fn, \"w\")\n",
    "                header_line = \"gt_theta,gt_degrees,gt_s,gt_delta,rmse_gt,theta,degrees,s,delta,rmse_cpd\\n\"\n",
    "                sv_list = [gt_theta,gt_degrees,gt_s,gt_delta,rmse_gt,theta,degrees,s,delta,rmse_cpd]\n",
    "                data_line =  \",\".join([str(i) for i in sv_list])\n",
    "                fp.write(header_line + data_line[:-1] + \"\\n\")\n",
    "                # Save images\n",
    "                res = (10000 / target_pixel_size, 10000 / target_pixel_size)  # convert um to cm for saving\n",
    "                gt_affine_HE_fn = os.path.join(output_dir, roi_id + \"_gt_affined.tif\")\n",
    "                if not os.path.exists(gt_affine_HE_fn): # TODO: Check if the resolution of the gt_affine_HE is correct!!!!\n",
    "                    tf.imwrite(gt_affine_HE_fn, gt_affined_HE_img, photometric='rgb', resolution=res, resolutionunit=\"CENTIMETER\")\n",
    "                cpt_affine_HE_fn = os.path.join(output_dir, roi_id + \"_\" + seg + \"_cpd_affined.tif\")\n",
    "                if not os.path.exists(cpt_affine_HE_fn):\n",
    "                    tf.imwrite(cpt_affine_HE_fn, cpd_affined_HE_img, photometric='rgb', resolution=res, resolutionunit=\"CENTIMETER\")\n",
    "                \n",
    "                # Save affined points\n",
    "                affined_points_fn = os.path.join(output_dir, roi_id + \"_\"+ seg +\"_affined_points.csv\")\n",
    "                fp = open(affined_points_fn, \"w\")\n",
    "                wrt_str = \"gt_aff_x,gt_aff_y,seg_aff_x,seg_aff_y\\n\"\n",
    "                for p_idx, _ in enumerate(cpd_affined_points):\n",
    "                    data_line_str = [str(gt_affined_points[p_idx, 0]), str(gt_affined_points[p_idx, 1]), \\\n",
    "                                     str(cpd_affined_points[p_idx, 0]), str(cpd_affined_points[p_idx, 1])]\n",
    "                    data_line =  \",\".join([str(i) for i in data_line_str])\n",
    "                    wrt_str += data_line[:-1] + \"\\n\"\n",
    "                fp.write(wrt_str)\n",
    "                \n",
    "        elif sec == \"Sec2\":\n",
    "            HE_img_dir = os.path.join(data_root_dir, \"FOVs\", \"HE_FOVs\", \"Rab_Spine-22R919-A-SERBSVG-5X-08\")\n",
    "\n",
    "            # Get image\n",
    "            he_fn = os.path.join(HE_img_dir, roi_id + \".tif\")\n",
    "            he_img = tf.TiffFile(he_fn).pages[0].asarray().astype(float)\n",
    "            \n",
    "            # Load ground truth transformation\n",
    "            ground_truth_affine_dir = os.path.join(data_root_dir, \"AlignmentEval\", \"Sec2GroundTruth\")\n",
    "            [gt_theta, gt_degrees, gt_s, gt_delta, gt_M, _] = load_trans(os.path.join(ground_truth_affine_dir, roi_id+\"_trans.dat\"))\n",
    "            \n",
    "            output_dir = os.path.join(data_root_dir, \"AlignmentEval\", \"ApplyAlignment\", \"Sec2Output\")\n",
    "            \n",
    "            for seg in seg_method_list:\n",
    "                print(\"Running %s, %s for %s\" % (roi_id, sec, seg))\n",
    "                \n",
    "                if seg == \"StarDist\":\n",
    "                    HE_points_dir = os.path.join(data_root_dir, \"AlignmentEval\", \"QuPathAnnoProj_HE_Sec2\", \"export\")\n",
    "                    MxIF_points_dir =os.path.join(data_root_dir, \"AlignmentEval\", \"QuPathAnnoProj_MxIF\", \"export\")\n",
    "                    cpd_affine_dir = os.path.join(data_root_dir, \"AlignmentEval\", \"Sec2_stardist_CPD\")\n",
    "                elif seg == \"Watershed\":\n",
    "                    HE_points_dir = os.path.join(data_root_dir, \"AlignmentEval\", \"QuPathAnnoProj_HE_Sec2_watershed\", \"export\")\n",
    "                    MxIF_points_dir =os.path.join(data_root_dir, \"AlignmentEval\", \"QuPathAnnoProj_MxIF_watershed\", \"export\")\n",
    "                    cpd_affine_dir = os.path.join(data_root_dir, \"AlignmentEval\", \"Sec2_watershed_CPD\")\n",
    "                else:\n",
    "                    raise Exception(\"Unknown segmentation method\")\n",
    "                \n",
    "                # Get points\n",
    "                HE_quant_fn = os.path.join(HE_points_dir, roi_id + \"_\" + seg + \"_QUANT.tsv\")\n",
    "                HE_points = get_cell_loc(HE_quant_fn)\n",
    "                MxIF_quant_fn = os.path.join(MxIF_points_dir, roi_id + \"_\" + seg + \"_QUANT.tsv\")\n",
    "                MxIF_points = get_cell_loc(MxIF_quant_fn)\n",
    "                \n",
    "                # apply transformation (from annotation) to points (from different cell segmentation methods) and image\n",
    "                gt_affined_points = apply_aff_trans2points(HE_points, gt_M)\n",
    "                gt_affined_HE_img = cv2.warpAffine(src=he_img, M=gt_M, dsize=dapi_img.shape)\n",
    "\n",
    "                # apply transformation (from CPD) to points (from different cell segmentation methods) and image\n",
    "                [theta, degrees, s, delta, M] = load_trans(os.path.join(cpd_affine_dir, roi_id+\"_trans.dat\"))\n",
    "                cpd_affined_points = apply_aff_trans2points(HE_points, M)\n",
    "                cpd_affined_HE_img = cv2.warpAffine(src=he_img, M=M, dsize=dapi_img.shape)\n",
    "                \n",
    "                rmse_gt = calculate_points_affine_rmse(MxIF_points, gt_affined_points, leafsize=10)\n",
    "                rmse_cpd = calculate_points_affine_rmse(MxIF_points, cpd_affined_points, leafsize=10)\n",
    "                \n",
    "                # Save metrics \n",
    "                csv_fn = os.path.join(output_dir, roi_id + \"_\" + seg + \"_metrics.csv\")\n",
    "                fp = open(csv_fn, \"w\")\n",
    "                header_line = \"gt_theta,gt_degrees,gt_s,gt_delta,rmse_gt,theta,degrees,s,delta,rmse_cpd\\n\"\n",
    "                sv_list = [gt_theta,gt_degrees,gt_s,gt_delta,rmse_gt,theta,degrees,s,delta,rmse_cpd]\n",
    "                data_line =  \",\".join([str(i) for i in sv_list])\n",
    "                fp.write(header_line + data_line[:-1] + \"\\n\")\n",
    "                # Save images\n",
    "                res = (10000 / target_pixel_size, 10000 / target_pixel_size)  # convert um to cm for saving\n",
    "                gt_affine_HE_fn = os.path.join(output_dir, roi_id + \"_gt_affined.tif\")\n",
    "                if not os.path.exists(gt_affine_HE_fn): # TODO: Check if the resolution of the gt_affine_HE is correct!!!!\n",
    "                    tf.imwrite(gt_affine_HE_fn, gt_affined_HE_img, photometric='rgb', resolution=res, resolutionunit=\"CENTIMETER\")\n",
    "                cpt_affine_HE_fn = os.path.join(output_dir, roi_id + \"_\" + seg + \"_cpd_affined.tif\")\n",
    "                if not os.path.exists(cpt_affine_HE_fn):\n",
    "                    tf.imwrite(cpt_affine_HE_fn, cpd_affined_HE_img, photometric='rgb', resolution=res, resolutionunit=\"CENTIMETER\")\n",
    "                \n",
    "                # Save affined points\n",
    "                affined_points_fn = os.path.join(output_dir, roi_id + \"_\"+ seg +\"_affined_points.csv\")\n",
    "                fp = open(affined_points_fn, \"w\")\n",
    "                wrt_str = \"gt_aff_x,gt_aff_y,seg_aff_x,seg_aff_y\\n\"\n",
    "                for p_idx, _ in enumerate(cpd_affined_points):\n",
    "                    data_line_str = [str(gt_affined_points[p_idx, 0]), str(gt_affined_points[p_idx, 1]), \\\n",
    "                                     str(cpd_affined_points[p_idx, 0]), str(cpd_affined_points[p_idx, 1])]\n",
    "                    data_line =  \",\".join([str(i) for i in data_line_str])\n",
    "                    wrt_str += data_line[:-1] + \"\\n\"\n",
    "                fp.write(wrt_str)\n",
    "        else:\n",
    "            raise Exception(\"Unknown section name\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
